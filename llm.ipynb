{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import requests\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_length= 16\n",
    "d_model = 64\n",
    "batch_size = 4\n",
    "num_heads = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding('cl100k_base')\n",
    "tokenized_text = encoding.encode(text)\n",
    "tokenized_text = torch.tensor(tokenized_text, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = int(len(tokenized_text) * 0.9)\n",
    "train_data = tokenized_text[:train_index]\n",
    "validation_data = tokenized_text[train_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data\n",
    "indexs = torch.randint(low=0, high=len(data) - token_length, size=(batch_size,))\n",
    "# 4 * 16 tensor\n",
    "x_batch = torch.stack([data[idx: idx + token_length] for idx in indexs])\n",
    "y_batch = torch.stack([data[idx + 1: idx + token_length + 1] for idx in indexs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" solutions and offerings. This involves matching the customer's needs with the appropriate products or\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.DataFrame(x_batch[0].numpy())\n",
    "encoding.decode(x_batch[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100069"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get max index of token\n",
    "max_token_value = tokenized_text.max().item()\n",
    "max_token_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5123, -0.6028,  1.3043,  ..., -1.6790,  0.9367, -0.3207],\n",
       "        [-0.2108, -0.7986,  1.2182,  ...,  0.7188, -0.9925, -0.7194],\n",
       "        [ 0.2154, -0.2422,  0.2529,  ...,  0.6183,  0.9441,  0.2124],\n",
       "        ...,\n",
       "        [-0.4560, -1.7594,  1.4394,  ..., -0.5974,  1.4885,  1.3696],\n",
       "        [ 0.5343,  2.5246, -0.1196,  ..., -0.8313, -0.1659, -1.3517],\n",
       "        [ 1.9935, -1.8589, -0.6141,  ..., -0.7727,  0.1055,  1.2830]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct a 100070 * 16 matrix, get input embedding\n",
    "input_embedding_table = nn.Embedding(max_token_value + 1, d_model)\n",
    "input_embedding_table.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_embedding = input_embedding_table(x_batch)\n",
    "y_batch_embedding = input_embedding_table(y_batch)\n",
    "x_batch_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get postional encoding\n",
    "# first 16 * 16 matrix\n",
    "postion_encoding_table = torch.zeros(token_length, d_model)\n",
    "# postion 16 * 1\n",
    "postion = torch.arange(0, token_length, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "# [:, 0::2], ':' = selecting all lines, '0::2' = starting from 0, step by step 2\n",
    "postion_encoding_table[:, 0::2] = torch.sin(postion * div_term)\n",
    "postion_encoding_table[:, 1::2] = torch.sin(postion * div_term)\n",
    "postion_encoding_table = postion_encoding_table.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "\n",
    "postion_encoding_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add postion embedding with input embedding\n",
    "x = x_batch_embedding + postion_encoding_table\n",
    "y = y_batch_embedding + postion_encoding_table\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wq = nn.Linear(d_model, d_model)\n",
    "Wk = nn.Linear(d_model, d_model)\n",
    "Wv = nn.Linear(d_model, d_model)\n",
    "# linear last two dimension do the matrix mul\n",
    "Q = Wq(x)\n",
    "K = Wk(x)\n",
    "V = Wv(x)\n",
    "\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 16, 16])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [4, 16, 4, 16] -> [4, 4, 16, 16]\n",
    "# why permute? To enable each head to do separate computing which is parallel computing\n",
    "# 说人话，就是考虑的是token_length与每个head维度之间的关系，而不是num_heads与别的关系；矩阵相乘是\n",
    "Q = Q.reshape(batch_size, token_length, num_heads, d_model//num_heads).permute(0, 2, 1, 3)\n",
    "K = K.reshape(batch_size, token_length, num_heads, d_model//num_heads).permute(0, 2, 1, 3)\n",
    "V = V.reshape(batch_size, token_length, num_heads, d_model//num_heads).permute(0, 2, 1, 3)\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the attension fomular\n",
    "output = Q @ K.transpose(-2, -1) / math.sqrt(d_model // num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.9216e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-1.5789e-01,  4.6748e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-2.5910e-01, -3.7053e-01, -3.1831e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-2.8675e-02, -5.0447e-01,  1.5097e-01,  ..., -1.0524e-01,\n",
       "                  -inf,        -inf],\n",
       "          [ 1.5891e-01, -2.8209e-01, -4.6384e-01,  ...,  1.6642e-01,\n",
       "           -4.1548e-01,        -inf],\n",
       "          [ 5.5566e-01, -8.8920e-02, -3.5326e-01,  ...,  2.4195e-01,\n",
       "            2.4298e-02,  1.0459e-01]],\n",
       "\n",
       "         [[-5.9204e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-1.6259e-01, -1.9450e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 5.8910e-02, -3.4836e-01, -2.8727e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [ 1.9950e-01,  5.9939e-01, -2.7870e-03,  ..., -7.5903e-01,\n",
       "                  -inf,        -inf],\n",
       "          [-4.5868e-01,  7.9500e-01,  3.4667e-01,  ...,  1.0558e-01,\n",
       "            1.9750e-01,        -inf],\n",
       "          [ 1.0282e-01, -2.7860e-01, -1.9286e-01,  ...,  5.1759e-01,\n",
       "           -2.4264e-01, -5.5284e-01]],\n",
       "\n",
       "         [[ 1.5014e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-1.6308e-01, -3.0320e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-2.3643e-02,  2.3237e-01,  1.8347e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-4.5962e-01,  3.6161e-01,  3.5685e-01,  ..., -2.0579e-01,\n",
       "                  -inf,        -inf],\n",
       "          [-4.3496e-01, -6.3868e-01, -5.3467e-01,  ..., -4.4208e-01,\n",
       "           -1.1521e-01,        -inf],\n",
       "          [-4.2039e-01, -6.1931e-01, -5.0830e-01,  ..., -1.7621e+00,\n",
       "           -3.4377e-01,  2.5255e-01]],\n",
       "\n",
       "         [[-5.5149e-02,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-3.9575e-02, -2.6229e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 4.2532e-01, -7.6792e-01,  3.7552e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-1.6783e-01, -1.0002e-01, -2.2187e-01,  ..., -1.0494e+00,\n",
       "                  -inf,        -inf],\n",
       "          [ 4.2875e-01, -4.9051e-01, -4.5768e-01,  ..., -1.0053e-01,\n",
       "           -5.8535e-01,        -inf],\n",
       "          [ 3.7939e-01,  2.8959e-01,  4.2982e-01,  ...,  4.7581e-01,\n",
       "           -3.4348e-02, -4.3587e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9670e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 6.5417e-01, -1.1199e+00,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 1.4837e-01, -1.1953e+00, -9.3064e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-2.0992e-01,  8.6592e-01,  8.6554e-01,  ..., -6.6937e-01,\n",
       "                  -inf,        -inf],\n",
       "          [ 2.4071e-01,  2.4620e-01, -8.8712e-02,  ..., -5.7032e-01,\n",
       "           -2.3554e-01,        -inf],\n",
       "          [ 2.4795e-01,  1.0474e-01,  1.4604e-01,  ..., -1.4175e-01,\n",
       "            1.1737e-01,  3.9768e-01]],\n",
       "\n",
       "         [[ 7.8838e-02,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 4.9114e-01,  7.7982e-02,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 2.9135e-02, -4.1810e-01,  1.4536e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [ 1.2140e-01,  1.5942e-01, -7.1969e-03,  ..., -1.3200e+00,\n",
       "                  -inf,        -inf],\n",
       "          [-2.4976e-01, -4.7423e-01, -3.8579e-01,  ..., -2.4182e-01,\n",
       "            2.8543e-01,        -inf],\n",
       "          [ 3.0093e-01, -1.6819e-01,  3.1132e-01,  ..., -7.5951e-01,\n",
       "           -8.8478e-01,  2.2828e-01]],\n",
       "\n",
       "         [[-4.2197e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 1.1988e-01, -3.2978e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 5.7508e-03,  3.5552e-02,  5.9656e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-2.3606e-01, -5.8729e-01, -4.4192e-02,  ...,  2.9779e-01,\n",
       "                  -inf,        -inf],\n",
       "          [-2.2525e-01,  1.6318e-01,  3.5045e-01,  ...,  2.6746e-01,\n",
       "           -2.5359e-01,        -inf],\n",
       "          [ 4.5113e-01,  3.6421e-01,  1.5580e-01,  ...,  3.0939e-01,\n",
       "            2.1924e-02,  7.8885e-01]],\n",
       "\n",
       "         [[-5.4660e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 4.3288e-01, -3.0861e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-1.9174e-01, -1.3663e-01, -3.5663e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [ 2.8212e-01,  1.2515e-01, -9.0864e-02,  ..., -1.4607e-01,\n",
       "                  -inf,        -inf],\n",
       "          [ 9.7427e-02,  2.1375e-02, -3.7391e-01,  ...,  3.8968e-01,\n",
       "            1.9824e-01,        -inf],\n",
       "          [-6.9385e-01, -1.4423e-01, -3.8467e-01,  ..., -4.1864e-01,\n",
       "            3.0674e-02, -4.2612e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 5.2350e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 1.2634e-01,  6.3634e-02,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-1.7907e-01, -1.8059e-01,  4.5340e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [ 1.0145e-01, -1.9732e-01, -1.9172e-01,  ..., -3.1331e-01,\n",
       "                  -inf,        -inf],\n",
       "          [-4.0582e-01,  5.4863e-01,  5.0073e-02,  ...,  3.2459e-01,\n",
       "            4.7890e-01,        -inf],\n",
       "          [ 1.9698e-01,  3.2662e-01, -4.0600e-01,  ...,  2.4033e-01,\n",
       "            2.6824e-01,  1.0459e-01]],\n",
       "\n",
       "         [[ 1.8553e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-2.6959e-02,  5.9048e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 1.2534e-02,  3.1465e-03, -3.4903e-02,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-7.9098e-01,  2.1986e-01,  8.0183e-01,  ...,  5.5415e-01,\n",
       "                  -inf,        -inf],\n",
       "          [-1.0217e-01,  1.8054e-01,  7.5949e-01,  ..., -1.5988e-01,\n",
       "           -6.7803e-02,        -inf],\n",
       "          [-5.9671e-02,  3.1305e-01, -9.7269e-02,  ...,  3.4001e-01,\n",
       "           -4.5088e-02, -5.5284e-01]],\n",
       "\n",
       "         [[ 4.0279e-02,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-2.3440e-01, -2.4949e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 9.6629e-02,  2.7784e-01, -2.9901e-02,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [ 6.4452e-01, -6.9272e-01,  3.0149e-01,  ...,  2.6486e-01,\n",
       "                  -inf,        -inf],\n",
       "          [ 4.9372e-01, -6.7594e-01,  3.8605e-01,  ..., -3.2253e-01,\n",
       "           -1.2357e-01,        -inf],\n",
       "          [ 4.6225e-02,  8.5824e-02,  2.1577e-01,  ..., -3.3331e-01,\n",
       "           -7.8134e-01,  2.5255e-01]],\n",
       "\n",
       "         [[-2.6957e-02,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 1.0401e+00,  4.7963e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-2.1668e-01,  1.0823e-01, -4.9258e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [ 1.2464e-01, -1.9988e-01, -4.6042e-02,  ..., -4.4090e-03,\n",
       "                  -inf,        -inf],\n",
       "          [ 4.6236e-02, -9.8961e-02,  6.5524e-01,  ..., -1.8715e-02,\n",
       "            1.6493e-01,        -inf],\n",
       "          [-1.1792e-01, -1.2809e-01,  8.5912e-02,  ...,  9.7441e-01,\n",
       "           -1.7849e-01, -4.3587e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.2053e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-7.7236e-01, -2.1526e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-3.6396e-01,  1.2039e-01,  1.9032e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [ 4.4278e-02,  3.1104e-01, -4.5216e-01,  ...,  6.4950e-02,\n",
       "                  -inf,        -inf],\n",
       "          [-3.5027e-01,  2.1586e-01,  8.1192e-02,  ..., -6.5421e-01,\n",
       "            3.9435e-01,        -inf],\n",
       "          [-3.5529e-01,  6.2561e-01, -2.0098e-01,  ..., -3.9247e-01,\n",
       "            2.0519e-01, -1.1903e-02]],\n",
       "\n",
       "         [[ 2.9850e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-3.3766e-01,  2.7175e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 3.6221e-01, -1.9549e-01,  9.0999e-02,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-5.3279e-01,  5.4136e-01,  1.5944e-01,  ..., -6.5644e-02,\n",
       "                  -inf,        -inf],\n",
       "          [-8.2730e-01,  7.0446e-01,  2.1264e-01,  ..., -9.1011e-02,\n",
       "            7.5766e-01,        -inf],\n",
       "          [-4.4117e-01, -6.5263e-03, -9.4280e-02,  ..., -8.4361e-02,\n",
       "            9.5538e-02,  3.8734e-01]],\n",
       "\n",
       "         [[-1.1689e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-2.0588e-01,  2.2731e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-2.1698e-01,  3.1295e-01,  1.0151e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-6.5265e-01,  1.1552e-01,  7.3409e-02,  ..., -3.1663e-01,\n",
       "                  -inf,        -inf],\n",
       "          [-1.5047e-01, -4.5394e-01, -3.2140e-01,  ...,  9.4605e-02,\n",
       "           -5.1539e-02,        -inf],\n",
       "          [-4.0815e-01,  5.2282e-01,  8.7307e-02,  ...,  6.7536e-02,\n",
       "            2.1760e-01, -3.1423e-01]],\n",
       "\n",
       "         [[-2.2729e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 6.2457e-02, -2.2155e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-4.7149e-01,  7.7332e-02, -1.8770e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-1.6453e-01,  1.0090e-03, -1.4063e-01,  ...,  4.2462e-02,\n",
       "                  -inf,        -inf],\n",
       "          [ 3.2044e-01, -2.2859e-01,  3.2781e-01,  ..., -2.7075e-01,\n",
       "            2.4075e-01,        -inf],\n",
       "          [ 2.0629e-01,  6.1130e-02, -2.1736e-01,  ..., -1.2344e-01,\n",
       "            5.8774e-02, -8.6829e-02]]]], grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the mask，矩阵上三角（不包括对角线取-inf)\n",
    "mask = torch.triu(torch.ones(token_length, token_length), diagonal=1).bool()\n",
    "output = output.masked_fill(mask, float('-inf'))\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3486, 0.6514, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3525, 0.3153, 0.3322,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0586, 0.0364, 0.0701,  ..., 0.0543, 0.0000, 0.0000],\n",
       "          [0.0693, 0.0446, 0.0372,  ..., 0.0698, 0.0390, 0.0000],\n",
       "          [0.1146, 0.0601, 0.0462,  ..., 0.0837, 0.0673, 0.0730]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5080, 0.4920, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4214, 0.2804, 0.2981,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0752, 0.1122, 0.0614,  ..., 0.0288, 0.0000, 0.0000],\n",
       "          [0.0345, 0.1209, 0.0772,  ..., 0.0607, 0.0665, 0.0000],\n",
       "          [0.0629, 0.0430, 0.0468,  ..., 0.0953, 0.0445, 0.0327]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5350, 0.4650, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2839, 0.3668, 0.3493,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0367, 0.0834, 0.0830,  ..., 0.0473, 0.0000, 0.0000],\n",
       "          [0.0440, 0.0359, 0.0398,  ..., 0.0437, 0.0605, 0.0000],\n",
       "          [0.0432, 0.0354, 0.0396,  ..., 0.0113, 0.0466, 0.0846]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5554, 0.4446, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4435, 0.1345, 0.4220,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0598, 0.0640, 0.0567,  ..., 0.0248, 0.0000, 0.0000],\n",
       "          [0.0935, 0.0373, 0.0385,  ..., 0.0551, 0.0339, 0.0000],\n",
       "          [0.0878, 0.0803, 0.0924,  ..., 0.0967, 0.0581, 0.0389]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.8550, 0.1450, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.6247, 0.1630, 0.2123,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0542, 0.1589, 0.1588,  ..., 0.0342, 0.0000, 0.0000],\n",
       "          [0.0884, 0.0889, 0.0636,  ..., 0.0393, 0.0549, 0.0000],\n",
       "          [0.0662, 0.0574, 0.0598,  ..., 0.0449, 0.0581, 0.0769]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.6018, 0.3982, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3620, 0.2314, 0.4066,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0837, 0.0869, 0.0736,  ..., 0.0198, 0.0000, 0.0000],\n",
       "          [0.0548, 0.0438, 0.0479,  ..., 0.0553, 0.0936, 0.0000],\n",
       "          [0.0724, 0.0453, 0.0731,  ..., 0.0251, 0.0221, 0.0673]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.6106, 0.3894, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2607, 0.2686, 0.4707,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0501, 0.0352, 0.0606,  ..., 0.0854, 0.0000, 0.0000],\n",
       "          [0.0402, 0.0592, 0.0714,  ..., 0.0657, 0.0390, 0.0000],\n",
       "          [0.0743, 0.0681, 0.0553,  ..., 0.0644, 0.0483, 0.1041]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.6773, 0.3227, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3443, 0.3638, 0.2919,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0988, 0.0845, 0.0680,  ..., 0.0644, 0.0000, 0.0000],\n",
       "          [0.0739, 0.0684, 0.0461,  ..., 0.0989, 0.0817, 0.0000],\n",
       "          [0.0406, 0.0704, 0.0554,  ..., 0.0535, 0.0839, 0.0531]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5157, 0.4843, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2577, 0.2573, 0.4850,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0736, 0.0546, 0.0549,  ..., 0.0486, 0.0000, 0.0000],\n",
       "          [0.0401, 0.1043, 0.0633,  ..., 0.0833, 0.0972, 0.0000],\n",
       "          [0.0765, 0.0871, 0.0419,  ..., 0.0799, 0.0822, 0.0698]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3504, 0.6496, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3396, 0.3365, 0.3239,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0280, 0.0769, 0.1375,  ..., 0.1074, 0.0000, 0.0000],\n",
       "          [0.0616, 0.0817, 0.1459,  ..., 0.0582, 0.0638, 0.0000],\n",
       "          [0.0475, 0.0690, 0.0458,  ..., 0.0709, 0.0482, 0.0290]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5038, 0.4962, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3247, 0.3892, 0.2861,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.1194, 0.0314, 0.0847,  ..., 0.0817, 0.0000, 0.0000],\n",
       "          [0.1148, 0.0357, 0.1031,  ..., 0.0508, 0.0619, 0.0000],\n",
       "          [0.0687, 0.0715, 0.0814,  ..., 0.0470, 0.0300, 0.0845]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.6365, 0.3635, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3182, 0.4403, 0.2415,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0831, 0.0601, 0.0701,  ..., 0.0730, 0.0000, 0.0000],\n",
       "          [0.0531, 0.0459, 0.0977,  ..., 0.0498, 0.0598, 0.0000],\n",
       "          [0.0555, 0.0550, 0.0681,  ..., 0.1655, 0.0523, 0.0404]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3642, 0.6358, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2292, 0.3719, 0.3989,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0789, 0.1030, 0.0480,  ..., 0.0805, 0.0000, 0.0000],\n",
       "          [0.0459, 0.0808, 0.0707,  ..., 0.0339, 0.0966, 0.0000],\n",
       "          [0.0404, 0.1077, 0.0471,  ..., 0.0389, 0.0708, 0.0569]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3522, 0.6478, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4283, 0.2452, 0.3265,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0442, 0.1294, 0.0883,  ..., 0.0705, 0.0000, 0.0000],\n",
       "          [0.0219, 0.1015, 0.0621,  ..., 0.0458, 0.1071, 0.0000],\n",
       "          [0.0399, 0.0616, 0.0564,  ..., 0.0570, 0.0682, 0.0913]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3934, 0.6066, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2455, 0.4170, 0.3375,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0386, 0.0831, 0.0797,  ..., 0.0540, 0.0000, 0.0000],\n",
       "          [0.0588, 0.0434, 0.0495,  ..., 0.0751, 0.0649, 0.0000],\n",
       "          [0.0414, 0.1049, 0.0679,  ..., 0.0665, 0.0773, 0.0454]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5705, 0.4295, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2463, 0.4265, 0.3272,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0553, 0.0652, 0.0566,  ..., 0.0680, 0.0000, 0.0000],\n",
       "          [0.0850, 0.0491, 0.0857,  ..., 0.0471, 0.0785, 0.0000],\n",
       "          [0.0683, 0.0591, 0.0447,  ..., 0.0491, 0.0590, 0.0510]]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax, dim = -1对每一行进行softmax\n",
    "attention_score = torch.softmax(output, dim=-1)\n",
    "attention_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 16, 16])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply attention @ V\n",
    "attention_output = attention_score @ V\n",
    "attention_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat\n",
    "attention_output = attention_output.transpose(1, 2).reshape(batch_size, token_length, d_model)\n",
    "attention_output.shape\n",
    "Wo = nn.Linear(d_model, d_model)\n",
    "output = Wo(attention_output)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer norm\n",
    "layer_norm = nn.LayerNorm(d_model)\n",
    "layer_norm_output = layer_norm(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FFN\n",
    "output = nn.Linear(d_model, d_model * 4)(layer_norm_output)\n",
    "output = nn.ReLU()(output)\n",
    "output = nn.Linear(d_model * 4, d_model)(output)\n",
    "# residual\n",
    "output = output + layer_norm_output\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 100070])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final linear layer\n",
    "output = nn.Linear(d_model, max_token_value + 1)(output)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39msoftmax(output, dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      2\u001b[0m logits\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "logits = nn.softmax(output, dim = -1)\n",
    "logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
