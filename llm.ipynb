{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import requests\n",
    "import tiktoken\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_length= 16\n",
    "d_model = 64\n",
    "batch_size = 4\n",
    "num_heads = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding('cl100k_base')\n",
    "tokenized_text = encoding.encode(text)\n",
    "tokenized_text = torch.tensor(tokenized_text, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = int(len(tokenized_text) * 0.9)\n",
    "train_data = tokenized_text[:train_index]\n",
    "validation_data = tokenized_text[train_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data\n",
    "indexs = torch.randint(low=0, high=len(data) - token_length, size=(batch_size,))\n",
    "# 4 * 16 tensor\n",
    "x_batch = torch.stack([data[idx: idx + token_length] for idx in indexs])\n",
    "y_batch = torch.stack([data[idx + 1: idx + token_length + 1] for idx in indexs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' you can identify the underlying motivations and desires. Through careful analysis and evaluation, customization'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.DataFrame(x_batch[0].numpy())\n",
    "encoding.decode(x_batch[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100069"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get max index of token\n",
    "max_token_value = tokenized_text.max().item()\n",
    "max_token_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0218, -0.1466, -1.0452,  ...,  0.3268, -0.6308, -1.1450],\n",
       "        [ 0.9685, -0.9843,  0.2110,  ..., -1.1781,  0.8842,  0.0057],\n",
       "        [-0.4306, -0.4919,  0.1680,  ..., -0.4137, -1.5682, -0.6410],\n",
       "        ...,\n",
       "        [ 0.4012,  0.6788, -0.0704,  ...,  0.2108,  0.0893, -0.0154],\n",
       "        [ 1.1024,  0.3350,  0.0199,  ...,  2.0194,  0.3359,  0.5032],\n",
       "        [-1.7695, -0.7623, -0.2536,  ..., -0.5876,  0.9567, -0.1181]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct a 100070 * 16 matrix, get input embedding\n",
    "input_embedding_table = nn.Embedding(max_token_value + 1, d_model)\n",
    "input_embedding_table.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_embedding = input_embedding_table(x_batch)\n",
    "y_batch_embedding = input_embedding_table(y_batch)\n",
    "x_batch_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get postional encoding\n",
    "# first 16 * 16 matrix\n",
    "postion_encoding_table = torch.zeros(token_length, d_model)\n",
    "# postion 16 * 1\n",
    "postion = torch.arange(0, token_length, dtype=torch.float).unsqueeze(1)\n",
    "div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "# [:, 0::2], ':' = selecting all lines, '0::2' = starting from 0, step by step 2\n",
    "postion_encoding_table[:, 0::2] = torch.sin(postion * div_term)\n",
    "postion_encoding_table[:, 1::2] = torch.sin(postion * div_term)\n",
    "postion_encoding_table = postion_encoding_table.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "\n",
    "postion_encoding_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add postion embedding with input embedding\n",
    "x = x_batch_embedding + postion_encoding_table\n",
    "y = y_batch_embedding + postion_encoding_table\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wq = nn.Linear(d_model, d_model)\n",
    "Wk = nn.Linear(d_model, d_model)\n",
    "Wv = nn.Linear(d_model, d_model)\n",
    "# linear last two dimension do the matrix mul\n",
    "Q = Wq(x)\n",
    "K = Wk(x)\n",
    "V = Wv(x)\n",
    "\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 16, 16])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [4, 16, 4, 16] -> [4, 4, 16, 16]\n",
    "# why permute? To enable each head to do separate computing which is parallel computing\n",
    "# 说人话，就是考虑的是token_length与每个head维度之间的关系，而不是num_heads与别的关系；矩阵相乘是\n",
    "Q = Q.reshape(batch_size, token_length, num_heads, d_model//num_heads).permute(0, 2, 1, 3)\n",
    "K = K.reshape(batch_size, token_length, num_heads, d_model//num_heads).permute(0, 2, 1, 3)\n",
    "V = V.reshape(batch_size, token_length, num_heads, d_model//num_heads).permute(0, 2, 1, 3)\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the attension fomular\n",
    "output = Q @ K.transpose(-2, -1) / math.sqrt(d_model // num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 8.4941e-02,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-2.3501e-01,  2.2545e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-2.1473e-01,  3.0864e-01, -5.7618e-02,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-1.2848e-01, -4.2314e-01,  1.2258e-01,  ..., -8.9928e-02,\n",
       "                  -inf,        -inf],\n",
       "          [-3.9670e-02,  1.6023e-01,  3.0037e-01,  ..., -2.4559e-01,\n",
       "            1.1694e-01,        -inf],\n",
       "          [-6.1681e-01,  3.7470e-01,  4.5829e-01,  ..., -6.7069e-01,\n",
       "           -1.0295e-01, -7.4017e-02]],\n",
       "\n",
       "         [[ 6.6310e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 3.9625e-01,  1.0919e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 7.7241e-01,  1.8229e-01, -3.6682e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-3.8157e-02, -5.7152e-02, -7.8375e-02,  ...,  2.0550e-01,\n",
       "                  -inf,        -inf],\n",
       "          [ 8.1262e-02,  2.7448e-01, -1.8887e-01,  ...,  1.0213e-01,\n",
       "           -2.9245e-02,        -inf],\n",
       "          [-1.0719e-01,  4.9037e-02, -5.5850e-01,  ...,  3.1300e-01,\n",
       "           -9.1119e-02,  1.5340e-01]],\n",
       "\n",
       "         [[-3.6707e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-3.1911e-03,  2.1600e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-1.1285e-01, -2.9885e-01,  7.7303e-02,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [ 6.9585e-02,  2.6636e-01, -1.0940e-01,  ..., -2.6983e-01,\n",
       "                  -inf,        -inf],\n",
       "          [ 8.9255e-03, -1.3311e-01,  2.3410e-01,  ..., -9.0153e-01,\n",
       "           -1.3280e-01,        -inf],\n",
       "          [ 2.0328e-01, -2.6136e-01,  2.3000e-01,  ..., -6.3951e-03,\n",
       "            7.0218e-02,  6.2271e-01]],\n",
       "\n",
       "         [[-4.3961e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 1.0865e-01, -2.8473e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 5.4943e-01, -1.3472e-01, -7.4511e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-2.2998e-01, -3.3057e-01, -1.8990e-01,  ...,  3.1486e-01,\n",
       "                  -inf,        -inf],\n",
       "          [ 4.9042e-01, -6.0275e-02, -7.5917e-01,  ..., -1.9286e-01,\n",
       "           -3.1014e-01,        -inf],\n",
       "          [ 5.9602e-01, -1.6377e-01,  6.9615e-02,  ...,  8.8466e-02,\n",
       "           -3.2583e-01, -4.2696e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.7152e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 5.5771e-01,  5.6190e-02,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 3.7501e-01, -1.7238e-01, -1.0926e+00,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-5.1646e-02,  3.8413e-01, -9.7002e-02,  ...,  3.1379e-01,\n",
       "                  -inf,        -inf],\n",
       "          [ 2.2451e-01, -2.5606e-01,  2.4067e-02,  ..., -8.2589e-02,\n",
       "           -2.6075e-01,        -inf],\n",
       "          [ 4.5711e-01,  4.0515e-01,  4.8799e-01,  ..., -1.8036e-01,\n",
       "           -1.6723e-01,  3.8887e-01]],\n",
       "\n",
       "         [[-1.0511e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 9.5293e-02,  4.3354e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-3.6385e-01,  8.4155e-02, -7.0411e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [ 3.2012e-01, -9.8975e-01, -2.9403e-01,  ..., -2.4252e-01,\n",
       "                  -inf,        -inf],\n",
       "          [ 1.0569e-01, -5.9239e-01,  1.5324e-01,  ..., -2.6142e-01,\n",
       "           -5.5915e-02,        -inf],\n",
       "          [-5.1199e-01, -2.2355e-02, -3.6677e-02,  ..., -4.5843e-01,\n",
       "           -2.5454e-03,  4.7766e-01]],\n",
       "\n",
       "         [[ 9.9065e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 4.4095e-01,  3.6840e-02,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-3.7690e-01,  7.4640e-01, -2.1369e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-2.0162e-03, -5.9680e-02, -1.4729e-01,  ...,  1.2664e-01,\n",
       "                  -inf,        -inf],\n",
       "          [ 7.6223e-01,  9.8643e-02,  7.0031e-04,  ...,  8.4124e-02,\n",
       "            1.9221e-01,        -inf],\n",
       "          [ 1.0102e+00, -1.1508e-01, -5.2120e-01,  ..., -7.5638e-01,\n",
       "           -2.4875e-01, -8.3394e-01]],\n",
       "\n",
       "         [[ 4.8938e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 3.3724e-01, -8.7723e-02,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-6.1391e-01, -4.1940e-01,  1.6098e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-1.3868e-02,  2.3632e-01,  5.6476e-01,  ...,  6.8280e-02,\n",
       "                  -inf,        -inf],\n",
       "          [ 3.3176e-01, -1.9573e-01,  5.6474e-01,  ..., -2.2470e-01,\n",
       "           -7.4441e-01,        -inf],\n",
       "          [ 2.5423e-01, -1.0126e-02,  1.7748e-01,  ..., -2.1530e-01,\n",
       "           -3.6901e-01, -7.3036e-01]]],\n",
       "\n",
       "\n",
       "        [[[-4.8215e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 9.4761e-02, -3.5630e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 3.4201e-01,  5.6325e-01,  5.9975e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-7.8547e-02, -3.2774e-02, -2.4642e-01,  ...,  5.9571e-01,\n",
       "                  -inf,        -inf],\n",
       "          [-3.6522e-01, -7.5280e-02, -2.2799e-01,  ..., -3.3409e-01,\n",
       "           -3.7841e-01,        -inf],\n",
       "          [ 6.1704e-01,  2.5096e-01, -1.4837e-01,  ...,  5.6344e-01,\n",
       "            1.4530e-01, -4.7962e-02]],\n",
       "\n",
       "         [[-4.3811e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-2.2137e-01, -5.7584e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 1.7590e-01, -6.4131e-02,  3.1766e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [ 1.9979e-01, -4.3012e-01, -6.9463e-01,  ...,  1.0389e-01,\n",
       "                  -inf,        -inf],\n",
       "          [ 7.1388e-03, -3.1102e-01, -6.6850e-01,  ...,  5.9962e-01,\n",
       "           -6.8913e-01,        -inf],\n",
       "          [-3.6218e-01,  6.4750e-02,  3.9237e-01,  ...,  5.7528e-02,\n",
       "            1.5500e-01,  2.3822e-01]],\n",
       "\n",
       "         [[ 1.3254e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-1.1014e-01, -2.0177e-02,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 4.0369e-02,  1.2028e-01,  3.4081e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-1.2011e-01,  3.8514e-01, -5.5770e-01,  ...,  3.8808e-01,\n",
       "                  -inf,        -inf],\n",
       "          [ 8.4896e-02,  2.6860e-01, -3.2435e-01,  ..., -5.0653e-02,\n",
       "            2.5896e-01,        -inf],\n",
       "          [-4.6886e-02, -7.3920e-02,  5.9367e-01,  ..., -1.9947e-01,\n",
       "           -3.3625e-02, -2.2245e-02]],\n",
       "\n",
       "         [[-7.5396e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-6.4594e-01, -4.7310e-02,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-3.5633e-01, -2.3626e-01, -3.5103e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [ 8.6747e-02, -1.5580e-01,  7.2153e-02,  ..., -1.9927e-01,\n",
       "                  -inf,        -inf],\n",
       "          [ 2.3079e-02, -4.1110e-01,  1.6069e-01,  ..., -1.3700e-01,\n",
       "            4.1705e-01,        -inf],\n",
       "          [ 6.0425e-01,  2.9389e-01, -7.2293e-01,  ...,  4.9332e-01,\n",
       "           -7.4430e-02,  3.1921e-01]]],\n",
       "\n",
       "\n",
       "        [[[-1.7203e-02,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-2.3027e-01, -8.5389e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-2.7476e-01, -8.0713e-01, -1.0152e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-4.4250e-01, -1.0385e+00,  2.6124e-01,  ..., -3.8159e-03,\n",
       "                  -inf,        -inf],\n",
       "          [-6.1559e-03, -2.0779e-01,  5.4035e-02,  ..., -1.7234e-02,\n",
       "           -2.7230e-01,        -inf],\n",
       "          [ 1.4082e-02,  3.3411e-01,  5.8956e-02,  ...,  5.1206e-01,\n",
       "            1.1473e-01, -1.5547e-01]],\n",
       "\n",
       "         [[ 3.7813e-02,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 7.7205e-02,  5.2392e-02,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-9.0894e-02, -2.4422e-02, -5.7328e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-1.7607e-01,  6.5311e-01,  4.0963e-01,  ...,  2.9480e-01,\n",
       "                  -inf,        -inf],\n",
       "          [-3.9831e-02, -3.7533e-01, -1.2016e-01,  ..., -1.3125e-01,\n",
       "            1.6501e-01,        -inf],\n",
       "          [-1.5158e-01, -3.7065e-01,  1.1118e-01,  ..., -3.0537e-01,\n",
       "           -1.5326e-01, -3.3797e-01]],\n",
       "\n",
       "         [[-5.3098e-03,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 4.7595e-01,  6.8658e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 2.5237e-01, -9.6703e-02, -5.2211e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [ 2.6383e-01,  9.1298e-01,  6.6221e-01,  ..., -2.0688e-01,\n",
       "                  -inf,        -inf],\n",
       "          [ 7.9459e-02,  2.6507e-01,  4.4800e-01,  ..., -2.5863e-01,\n",
       "           -1.0547e-01,        -inf],\n",
       "          [-2.5897e-01,  1.6087e-01,  4.7775e-02,  ..., -6.9086e-02,\n",
       "           -2.4727e-01, -2.7807e-01]],\n",
       "\n",
       "         [[-3.2952e-01,        -inf,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [ 3.9808e-02,  1.2287e-01,        -inf,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          [-1.7210e-02, -2.4243e-01, -4.1638e-01,  ...,        -inf,\n",
       "                  -inf,        -inf],\n",
       "          ...,\n",
       "          [-3.3458e-01, -1.2205e-01, -6.5493e-02,  ..., -3.3869e-01,\n",
       "                  -inf,        -inf],\n",
       "          [-4.4370e-01, -9.0857e-02,  4.2191e-01,  ..., -5.7983e-01,\n",
       "           -1.2280e-01,        -inf],\n",
       "          [-1.1503e-01, -5.0025e-02, -5.0727e-01,  ...,  3.5228e-01,\n",
       "            9.6604e-02, -6.5703e-01]]]], grad_fn=<MaskedFillBackward0>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the mask，矩阵上三角（不包括对角线取-inf)\n",
    "mask = torch.triu(torch.ones(token_length, token_length), diagonal=1).bool()\n",
    "output = output.masked_fill(mask, float('-inf'))\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3869, 0.6131, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2592, 0.4375, 0.3033,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0614, 0.0457, 0.0789,  ..., 0.0638, 0.0000, 0.0000],\n",
       "          [0.0487, 0.0595, 0.0684,  ..., 0.0396, 0.0569, 0.0000],\n",
       "          [0.0282, 0.0759, 0.0825,  ..., 0.0267, 0.0471, 0.0484]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5713, 0.4287, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5335, 0.2957, 0.1708,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0520, 0.0511, 0.0500,  ..., 0.0664, 0.0000, 0.0000],\n",
       "          [0.0810, 0.0983, 0.0618,  ..., 0.0827, 0.0725, 0.0000],\n",
       "          [0.0543, 0.0635, 0.0346,  ..., 0.0826, 0.0552, 0.0705]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4454, 0.5546, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3290, 0.2731, 0.3979,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0666, 0.0811, 0.0557,  ..., 0.0475, 0.0000, 0.0000],\n",
       "          [0.0658, 0.0571, 0.0824,  ..., 0.0265, 0.0571, 0.0000],\n",
       "          [0.0680, 0.0428, 0.0699,  ..., 0.0552, 0.0596, 0.1035]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5971, 0.4029, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5623, 0.2837, 0.1541,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0516, 0.0467, 0.0537,  ..., 0.0890, 0.0000, 0.0000],\n",
       "          [0.1194, 0.0689, 0.0342,  ..., 0.0603, 0.0536, 0.0000],\n",
       "          [0.0985, 0.0461, 0.0582,  ..., 0.0593, 0.0392, 0.0354]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.6228, 0.3772, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5528, 0.3198, 0.1274,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0653, 0.1009, 0.0624,  ..., 0.0941, 0.0000, 0.0000],\n",
       "          [0.0848, 0.0524, 0.0694,  ..., 0.0624, 0.0522, 0.0000],\n",
       "          [0.0750, 0.0712, 0.0773,  ..., 0.0396, 0.0401, 0.0700]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4162, 0.5838, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3052, 0.4777, 0.2172,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0870, 0.0235, 0.0471,  ..., 0.0496, 0.0000, 0.0000],\n",
       "          [0.0686, 0.0341, 0.0719,  ..., 0.0475, 0.0583, 0.0000],\n",
       "          [0.0370, 0.0604, 0.0595,  ..., 0.0390, 0.0616, 0.0995]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5997, 0.4003, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.1904, 0.5855, 0.2241,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0641, 0.0605, 0.0554,  ..., 0.0729, 0.0000, 0.0000],\n",
       "          [0.1217, 0.0627, 0.0568,  ..., 0.0618, 0.0688, 0.0000],\n",
       "          [0.1773, 0.0575, 0.0383,  ..., 0.0303, 0.0503, 0.0280]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.6047, 0.3953, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2280, 0.2770, 0.4949,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0700, 0.0899, 0.1249,  ..., 0.0760, 0.0000, 0.0000],\n",
       "          [0.0801, 0.0473, 0.1011,  ..., 0.0459, 0.0273, 0.0000],\n",
       "          [0.0933, 0.0716, 0.0864,  ..., 0.0584, 0.0500, 0.0349]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.6109, 0.3891, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2824, 0.3523, 0.3654,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0486, 0.0508, 0.0411,  ..., 0.0953, 0.0000, 0.0000],\n",
       "          [0.0471, 0.0629, 0.0540,  ..., 0.0486, 0.0465, 0.0000],\n",
       "          [0.1027, 0.0712, 0.0478,  ..., 0.0974, 0.0641, 0.0528]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5877, 0.4123, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3403, 0.2677, 0.3921,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0650, 0.0346, 0.0266,  ..., 0.0591, 0.0000, 0.0000],\n",
       "          [0.0508, 0.0370, 0.0259,  ..., 0.0919, 0.0253, 0.0000],\n",
       "          [0.0446, 0.0683, 0.0948,  ..., 0.0678, 0.0747, 0.0812]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4775, 0.5225, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.2912, 0.3155, 0.3933,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0515, 0.0854, 0.0333,  ..., 0.0857, 0.0000, 0.0000],\n",
       "          [0.0604, 0.0725, 0.0401,  ..., 0.0527, 0.0719, 0.0000],\n",
       "          [0.0681, 0.0663, 0.1293,  ..., 0.0585, 0.0691, 0.0698]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3547, 0.6453, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3192, 0.3599, 0.3209,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0733, 0.0575, 0.0723,  ..., 0.0551, 0.0000, 0.0000],\n",
       "          [0.0693, 0.0449, 0.0795,  ..., 0.0591, 0.1028, 0.0000],\n",
       "          [0.0994, 0.0729, 0.0264,  ..., 0.0890, 0.0504, 0.0747]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.6510, 0.3490, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3602, 0.2115, 0.4283,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0337, 0.0186, 0.0681,  ..., 0.0522, 0.0000, 0.0000],\n",
       "          [0.0625, 0.0511, 0.0664,  ..., 0.0618, 0.0479, 0.0000],\n",
       "          [0.0563, 0.0775, 0.0589,  ..., 0.0926, 0.0622, 0.0475]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.5062, 0.4938, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.3723, 0.3979, 0.2298,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0428, 0.0980, 0.0769,  ..., 0.0685, 0.0000, 0.0000],\n",
       "          [0.0699, 0.0500, 0.0645,  ..., 0.0638, 0.0858, 0.0000],\n",
       "          [0.0593, 0.0476, 0.0771,  ..., 0.0508, 0.0592, 0.0492]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4475, 0.5525, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4616, 0.3256, 0.2128,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0852, 0.1631, 0.1269,  ..., 0.0532, 0.0000, 0.0000],\n",
       "          [0.0776, 0.0934, 0.1121,  ..., 0.0553, 0.0645, 0.0000],\n",
       "          [0.0506, 0.0770, 0.0687,  ..., 0.0611, 0.0512, 0.0496]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4792, 0.5208, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.4050, 0.3233, 0.2717,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0524, 0.0648, 0.0686,  ..., 0.0522, 0.0000, 0.0000],\n",
       "          [0.0390, 0.0555, 0.0926,  ..., 0.0340, 0.0537, 0.0000],\n",
       "          [0.0530, 0.0565, 0.0358,  ..., 0.0845, 0.0655, 0.0308]]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# softmax, dim = -1对每一行进行softmax\n",
    "attention_score = torch.softmax(output, dim=-1)\n",
    "attention_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 16, 16])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply attention @ V\n",
    "attention_output = attention_score @ V\n",
    "attention_output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concat\n",
    "attention_output = attention_output.transpose(1, 2).reshape(batch_size, token_length, d_model)\n",
    "attention_output.shape\n",
    "Wo = nn.Linear(d_model, d_model)\n",
    "output = Wo(attention_output)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer norm\n",
    "layer_norm = nn.LayerNorm(d_model)\n",
    "layer_norm_output = layer_norm(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 64])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FFN\n",
    "output = nn.Linear(d_model, d_model * 4)(layer_norm_output)\n",
    "output = nn.ReLU()(output)\n",
    "output = nn.Linear(d_model * 4, d_model)(output)\n",
    "# residual\n",
    "output = output + layer_norm_output\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 16, 100070])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final linear layer\n",
    "output = nn.Linear(d_model, max_token_value + 1)(output)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' ambitious'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.softmax(output, dim = -1)\n",
    "logits.shape\n",
    "encoding.decode([torch.argmax(logits[0, 0]).item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2+cpu\n",
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())  #输出为True，则安装无误"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
